{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local[*] means make use of all available cores on the system and distribute the tasks through its own cluster\n",
    "# manager i.e spark cluster manager.\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"SimilarMaovies\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_rdd = sc.textFile('file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files/ml-100k/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(base_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_function(line):\n",
    "    info = line.split()\n",
    "    user_id = int(info[0])\n",
    "    movie_id = int(info[1])\n",
    "    \n",
    "    rating = float(info[2])\n",
    "    \n",
    "    return (user_id,(movie_id,rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_movie_rating_rdd = base_rdd.map(split_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(user_movie_rating_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(user_movie_rating_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_ratings_on_same_user_rdd = user_movie_rating_rdd.join(user_movie_rating_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200812\n"
     ]
    }
   ],
   "source": [
    "print(joined_ratings_on_same_user_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(943, ((1330, 3.0), (1330, 3.0))), (943, ((1330, 3.0), (1228, 3.0))), (943, ((1330, 3.0), (1188, 3.0))), (943, ((1330, 3.0), (1074, 4.0))), (943, ((1330, 3.0), (1067, 2.0))), (943, ((1330, 3.0), (1047, 2.0))), (943, ((1330, 3.0), (1044, 3.0))), (943, ((1330, 3.0), (1028, 2.0))), (943, ((1330, 3.0), (1011, 2.0))), (943, ((1330, 3.0), (943, 5.0)))]\n"
     ]
    }
   ],
   "source": [
    "print(joined_ratings_on_same_user_rdd.top(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_function(user_movies):\n",
    "    movie1,rating1 = user_movies[1][0]\n",
    "    movie2,rating2 = user_movies[1][1]\n",
    "    return movie1 < movie2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_joined_ratings_rdd = joined_ratings_on_same_user_rdd.filter(filter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10050406\n"
     ]
    }
   ],
   "source": [
    "print(unique_joined_ratings_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(943, ((1228, 3.0), (1330, 3.0))), (943, ((1188, 3.0), (1330, 3.0))), (943, ((1188, 3.0), (1228, 3.0))), (943, ((1074, 4.0), (1330, 3.0))), (943, ((1074, 4.0), (1228, 3.0))), (943, ((1074, 4.0), (1188, 3.0))), (943, ((1067, 2.0), (1330, 3.0))), (943, ((1067, 2.0), (1228, 3.0))), (943, ((1067, 2.0), (1188, 3.0))), (943, ((1067, 2.0), (1074, 4.0)))]\n"
     ]
    }
   ],
   "source": [
    "print(unique_joined_ratings_rdd.top(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constructing movie id to movie name rdd\n",
    "movie_item_rdd = sc.textFile('file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files/ml-100k/u.item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_function(line):\n",
    "    info = line.split(\"|\")\n",
    "    movie_id = int(info[0])\n",
    "    movie_name = info[1].encode('ascii','ignore')\n",
    "    return (movie_id,movie_name.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieid_name_rdd = movie_item_rdd.map(map_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n"
     ]
    }
   ],
   "source": [
    "print(movieid_name_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1682, 'Scream of Stone (Schrei aus Stein) (1991)'), (1681, 'You So Crazy (1994)'), (1680, 'Sliding Doors (1998)'), (1679, 'B. Monkey (1998)'), (1678, \"Mat' i syn (1997)\"), (1677, 'Sweet Nothing (1995)'), (1676, 'War at Home, The (1996)'), (1675, 'Sunchaser, The (1996)'), (1674, 'Mamma Roma (1962)'), (1673, 'Mirage (1995)')]\n"
     ]
    }
   ],
   "source": [
    "print(movieid_name_rdd.top(10))\n",
    "# print(movieid_name_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sliding Doors (1998)']\n",
      "(1682, 'Scream of Stone (Schrei aus Stein) (1991)')\n",
      "(1, 'Toy Story (1995)')\n"
     ]
    }
   ],
   "source": [
    "print(movieid_name_rdd.lookup(1680))\n",
    "print(movieid_name_rdd.max())\n",
    "print(movieid_name_rdd.min())   \n",
    "\n",
    "# all above are actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOW lets continue with unique_joined_ratings_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_movies_and_getaway_with_user(line):\n",
    "    tuple_info = line[1]\n",
    "    \n",
    "    movie1,rating1 = tuple_info[0]\n",
    "    movie2,rating2 = tuple_info[1]\n",
    "    \n",
    "    return ((movie1,movie2),(rating1,rating2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_ratings_rdd = unique_joined_ratings_rdd.map(shuffle_movies_and_getaway_with_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10050406\n"
     ]
    }
   ],
   "source": [
    "print(movies_ratings_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1679, 1680), (3.0, 2.0)), ((1678, 1680), (1.0, 2.0)), ((1678, 1679), (1.0, 3.0)), ((1675, 1676), (3.0, 2.0)), ((1672, 1681), (2.0, 3.0))]\n"
     ]
    }
   ],
   "source": [
    "print(movies_ratings_rdd.top(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped_movies_ratings_all_users_rdd = movies_ratings_rdd.groupByKey()\n",
    "# whenever we apply groupByKey on rdd then as a value it gives you list of values along with a key\n",
    "# so in this case value would be list of tuples with a key as unique movie pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983206\n"
     ]
    }
   ],
   "source": [
    "print(grouped_movies_ratings_all_users_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1679, 1680), <pyspark.resultiterable.ResultIterable object at 0x10592d0b8>), ((1678, 1680), <pyspark.resultiterable.ResultIterable object at 0x10592d940>), ((1678, 1679), <pyspark.resultiterable.ResultIterable object at 0x10592dc50>), ((1675, 1676), <pyspark.resultiterable.ResultIterable object at 0x101d4c5f8>), ((1672, 1681), <pyspark.resultiterable.ResultIterable object at 0x1056d8390>), ((1669, 1670), <pyspark.resultiterable.ResultIterable object at 0x105918630>), ((1668, 1670), <pyspark.resultiterable.ResultIterable object at 0x10592db38>), ((1668, 1669), <pyspark.resultiterable.ResultIterable object at 0x105918e80>), ((1667, 1670), <pyspark.resultiterable.ResultIterable object at 0x10592deb8>), ((1667, 1669), <pyspark.resultiterable.ResultIterable object at 0x10592d898>)]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_movies_ratings_all_users_rdd.top(10))\n",
    "# unique movie pair to list of tuples i.e rating tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now it is time to compute cosine similarity\n",
    "# Remember that while applying mapValues(), key would remain the same --> only change will be reflected to values \n",
    "# and keys would remain the same, so [key would map to modifiedValue]\n",
    "\n",
    "# Very important thing is : while applying flatMapValues(), then one value associated with key (one element) would \n",
    "# be converted to many values with a same key (many elements in RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def cosineSimilarity(ratings):\n",
    "    list_of_ratings_tuple = ratings\n",
    "    sum_xx = sum_yy = sum_xy = 0\n",
    "    no_of_users_rated = 0\n",
    "    for rating_tuple in list_of_ratings_tuple:\n",
    "        sum_xx += rating_tuple[0] * rating_tuple[0]\n",
    "        sum_yy += rating_tuple[1] * rating_tuple[1]\n",
    "        sum_xy += rating_tuple[0] * rating_tuple[1]\n",
    "        no_of_users_rated += 1\n",
    "        \n",
    "    numerator = sum_xy\n",
    "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "    \n",
    "    rating = 0\n",
    "    if denominator:\n",
    "        rating = float(numerator)/denominator\n",
    "    \n",
    "    return (rating,no_of_users_rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_similarities_rdd = grouped_movies_ratings_all_users_rdd.mapValues(cosineSimilarity).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983206\n"
     ]
    }
   ],
   "source": [
    "print(movies_similarities_rdd.count())\n",
    "# As we cached movies_similarities_rdd, so execution of movies_similarities_rdd.count() would speed up  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1679, 1680), (1.0, 1)), ((1678, 1680), (1.0, 1)), ((1678, 1679), (1.0, 1)), ((1675, 1676), (1.0, 1)), ((1672, 1681), (1.0, 1)), ((1669, 1670), (1.0, 1)), ((1668, 1670), (1.0, 1)), ((1668, 1669), (1.0, 1)), ((1667, 1670), (1.0, 1)), ((1667, 1669), (1.0, 1))]\n"
     ]
    }
   ],
   "source": [
    "print(movies_similarities_rdd.top(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 movies similar to the movie provided here\n",
    "movie_id = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# closer the cosine similarity is to the one, more better is the situation\n",
    "# cosine similarity as 1 is ideal\n",
    "\n",
    "def filter_out_given_movies(line):\n",
    "    movie1,movie2 = line[0]\n",
    "    similarity = line[1][0]\n",
    "    no_of_users_rated = line[1][1]\n",
    "    \n",
    "    if (movie1 == movie_id or movie2 == movie_id) and similarity > 0.97 and no_of_users_rated > 50:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_movie_similarities_rdd = movies_similarities_rdd.filter(filter_out_given_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_rdd_to_sort = filtered_movie_similarities_rdd.map(lambda x: (x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_ten_similar_movie_list = reverse_rdd_to_sort.sortByKey(ascending=False).take(10)\n",
    "# take is an action which returns top 10 elements of rdd in a list\n",
    "# So take() is very similar to the top() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[((0.9895522078385338, 345), (50, 172)), ((0.9857230861253026, 480), (50, 181)), ((0.981760098872619, 380), (50, 174)), ((0.9789385605497993, 68), (50, 141)), ((0.9776576120448436, 109), (50, 178)), ((0.9775948291054827, 92), (50, 408)), ((0.9764692222674887, 138), (50, 498)), ((0.9751512937740359, 204), (50, 194)), ((0.9748681355460885, 103), (50, 169)), ((0.9741816128302572, 58), (50, 114))]\n"
     ]
    }
   ],
   "source": [
    "print(type(top_ten_similar_movie_list))\n",
    "print(top_ten_similar_movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies which are similar to Star Wars (1977) movie are :\n",
      "Empire Strikes Back, The (1980) movie with 0.9895522078385338 similarity           and 345 no of users rated\n",
      "Return of the Jedi (1983) movie with 0.9857230861253026 similarity           and 480 no of users rated\n",
      "Raiders of the Lost Ark (1981) movie with 0.981760098872619 similarity           and 380 no of users rated\n",
      "20,000 Leagues Under the Sea (1954) movie with 0.9789385605497993 similarity           and 68 no of users rated\n",
      "12 Angry Men (1957) movie with 0.9776576120448436 similarity           and 109 no of users rated\n",
      "Close Shave, A (1995) movie with 0.9775948291054827 similarity           and 92 no of users rated\n",
      "African Queen, The (1951) movie with 0.9764692222674887 similarity           and 138 no of users rated\n",
      "Sting, The (1973) movie with 0.9751512937740359 similarity           and 204 no of users rated\n",
      "Wrong Trousers, The (1993) movie with 0.9748681355460885 similarity           and 103 no of users rated\n",
      "Wallace & Gromit: The Best of Aardman Animation (1996) movie with 0.9741816128302572 similarity           and 58 no of users rated\n"
     ]
    }
   ],
   "source": [
    "print(f'Top 10 movies which are similar to {movieid_name_rdd.lookup(movie_id)[0]} movie are :')\n",
    "\n",
    "for item in top_ten_similar_movie_list:\n",
    "    similarity = item[0][0]\n",
    "    no_of_users_rated = item[0][1]\n",
    "    \n",
    "    movie1 = item[1][0]\n",
    "    movie2 = item[1][1]\n",
    "    \n",
    "    other_movie_id = movie1\n",
    "    if movie1 == movie_id:\n",
    "        other_movie_id = movie2\n",
    "    print(f'{movieid_name_rdd.lookup(other_movie_id)[0]} movie with {similarity} similarity \\\n",
    "          and {no_of_users_rated} no of users rated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can take any rdd and then call .saveAsTextFile(<name_of_file>) on that rdd to save results as a text file\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
