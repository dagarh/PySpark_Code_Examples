{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"recreate1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=recreate1>\n",
      "<class 'pyspark.context.SparkContext'>\n"
     ]
    }
   ],
   "source": [
    "print(sc)\n",
    "print(type(sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files_FraneKane/ml-100k/u.data MapPartitionsRDD[5] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(\"file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files_FraneKane/ml-100k/u.data\")\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def required_function(line):\n",
    "    data = line.split()\n",
    "    return Row(user_id=int(data[0]),movie_id=int(data[1]),rating=int(data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here converting unstructured data into structured data with the help of RDD\n",
    "row_dataset = rdd.map(required_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[8] at RDD at PythonRDD.scala:48\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "100000\n",
      "[Row(movie_id=242, rating=3, user_id=196), Row(movie_id=302, rating=3, user_id=186), Row(movie_id=377, rating=1, user_id=22)]\n"
     ]
    }
   ],
   "source": [
    "print(row_dataset)\n",
    "print(type(row_dataset))\n",
    "print(row_dataset.count())\n",
    "print(row_dataset.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(row_dataset).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[movie_id: bigint, rating: bigint, user_id: bigint]\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------+\n",
      "|movie_id|rating|user_id|\n",
      "+--------+------+-------+\n",
      "|     242|     3|    196|\n",
      "|     302|     3|    186|\n",
      "|     377|     1|     22|\n",
      "|      51|     2|    244|\n",
      "|     346|     1|    166|\n",
      "|     474|     4|    298|\n",
      "|     265|     2|    115|\n",
      "|     465|     5|    253|\n",
      "|     451|     3|    305|\n",
      "|      86|     3|      6|\n",
      "|     257|     2|     62|\n",
      "|    1014|     5|    286|\n",
      "|     222|     5|    200|\n",
      "|      40|     3|    210|\n",
      "|      29|     3|    224|\n",
      "|     785|     3|    303|\n",
      "|     387|     5|    122|\n",
      "|     274|     2|    194|\n",
      "|    1042|     4|    291|\n",
      "|    1184|     2|    234|\n",
      "+--------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.group.GroupedData object at 0x1083029e8>\n"
     ]
    }
   ],
   "source": [
    "grouped_object = df.groupBy('rating')\n",
    "print(grouped_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[rating: bigint, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "another_df = grouped_object.count()\n",
    "print(another_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|     1| 6110|\n",
      "|     2|11370|\n",
      "|     3|27145|\n",
      "|     4|34174|\n",
      "|     5|21201|\n",
      "+------+-----+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(another_df.orderBy('rating').show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
