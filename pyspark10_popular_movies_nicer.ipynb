{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this we would learn about the concept of broadcast variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We should broadcase python objects so that it can be sent to every worker node once and store it there for \n",
    "# efficiency. Worker node can use that python object whenever needed (no need to fetch it from master)\n",
    "\n",
    "# if you don't use broadcast() then master node would end up sending object to worker nodes multiple times and it \n",
    "# would be inefficient if object is so huge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBroadcast objects to the executors, such that they are always there whenever needed\\n\\nJust use sc.broadcast() to ship off whatever you want\\n\\nThen Use .value() to get the shipped object back on executors  \\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Broadcast objects to the executors, such that they are always there whenever needed\n",
    "\n",
    "Just use sc.broadcast() to ship off whatever you want\n",
    "\n",
    "Then Use .value to get the shipped object back on executors  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"PopularMovieNicer\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moviename_dict():\n",
    "    moviename = dict()\n",
    "    # opening file in binary format since it is having one byte character i.e é\n",
    "    with open('/Users/hdagar3/Documents/Spark_Things/Spark_Course_Files/ml-100k/u.item','rb') as f:\n",
    "        for line in f:   # line is chunk of bytes now\n",
    "            info = line.split(bytes('|',encoding=\"utf-8\"))  # to split bytes, we need byte character\n",
    "            moviename[int(info[0])] = info[1]\n",
    "    return moviename\n",
    "\n",
    "# dictionary = get_moviename_dict()\n",
    "\n",
    "# for key,value in dictionary.items():\n",
    "#    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sdfé>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<sdfé>'.encode(\"utf-8\").decode()  # encoding on string but decoding on byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<678', 'dfé>']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<678|dfé>'.split('|')    # <string>.split(<string>)  --> right\n",
    "                          # <bytes>.split(<bytes>)    --> right\n",
    "                          # <string>.split(<bytes>)   --> wrong\n",
    "                          # <byte>.split(<string>)    --> wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'678', b'df\\xc3\\xa9']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'678|dfé'.encode(\"utf-8\").split(bytes('|',encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_rdd = sc.textFile('file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files/ml-100k/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictFetcher = sc.broadcast(get_moviename_dict())  # it will broadcast this to all worker nodes in a cluster\n",
    "# dictionary can be fetched from this dictFetcher using .value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_one_rdd = base_rdd.map(lambda line : (int(line.split()[1]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_noofwatches_rdd = movie_one_rdd.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "noofwatches_movie_rdd = movie_noofwatches_rdd.map(lambda x:(x[1],x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_rdd = noofwatches_movie_rdd.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = sorted_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_original_dict = dictFetcher.value # it is giving us a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    print(result[0],my_original_dict[result[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
