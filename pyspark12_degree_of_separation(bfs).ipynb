{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local appName=Application>\n"
     ]
    }
   ],
   "source": [
    "from getsparkcontext import sc\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marvel_graph_rdd = sc.textFile('file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files/Marvel-Graph.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///Users/hdagar3/Documents/Spark_Things/Spark_Course_Files/Marvel-Graph.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print(marvel_graph_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6589\n"
     ]
    }
   ],
   "source": [
    "print(marvel_graph_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(marvel_graph_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn Spark you must know about the elements of RDD, i.e whenever you apply map operation on RDD then one by one, all\\nelements get processed in it.\\nGenerally we prefer element of RDD to be a string or tuple or list --> so whenever we are applying map operation then\\nyou would get either string(very initial) or tuple(after processing) or list(rare)\\n\\n\\nWhenever we use flatMap() on rdd then try to collect items in list then after processing, each item in list would \\nbecome the element of RDD i.e after returning the list, all elements of list would become elements of RDD . \\n--> V.V. IM Concept\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "In Spark you must know about the elements of RDD, i.e whenever you apply map operation on RDD then one by one, all\n",
    "elements get processed in it.\n",
    "Generally we prefer element of RDD to be a string or tuple or list --> so whenever we are applying map operation then\n",
    "you would get either string(very initial) or tuple(after processing) or list(rare)\n",
    "\n",
    "\n",
    "Whenever we use flatMap() on rdd then try to collect items in list then after processing, each item in list would \n",
    "become the element of RDD i.e after returning the list, all elements of list would become elements of RDD . \n",
    "--> V.V. IM Concept\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9223372036854775807\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "start_superhero_id = 5\n",
    "end_superhero_id = 14\n",
    "\n",
    "print(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeAdjacencyList(line):\n",
    "    info = line.split()\n",
    "    super_hero_id = int(info[0])\n",
    "    \n",
    "    links = list()\n",
    "    \n",
    "    for item in info[1:]:\n",
    "        links.append(int(item))\n",
    "    \n",
    "    color = 'WHITE'\n",
    "    distance = sys.maxsize\n",
    "    \n",
    "    if super_hero_id == start_superhero_id:\n",
    "        color = 'GRAY'\n",
    "        distance = 0\n",
    "    \n",
    "    return (super_hero_id,(links,distance,color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjacency_list_rdd = marvel_graph_rdd.map(makeAdjacencyList)\n",
    "# adjacency_list_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whenever this count becomes 1 then stop searching further, we have found end_superhero_id\n",
    "# it is accumulator i.e it will be shared among all the executors i.e all the worker nodes.\n",
    "count = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_each_element(line):\n",
    "    superhero_id = line[0]\n",
    "    links_list = line[1][0]\n",
    "    distance = line[1][1]\n",
    "    color = line[1][2]\n",
    "    \n",
    "    list_of_elements = list()\n",
    "    if color == 'GRAY':\n",
    "        if(superhero_id == end_superhero_id):\n",
    "                count.add(1)\n",
    "                \n",
    "        for item in links_list:\n",
    "            list_of_elements.append((item,([],distance+1,'GRAY')))\n",
    "        \n",
    "        color = 'BLACK'\n",
    "    list_of_elements.append(line)\n",
    "    \n",
    "    return list_of_elements            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reducer_of_superheros(tuple1,tuple2):\n",
    "    \n",
    "    links1 = tuple1[0]\n",
    "    distance1 = tuple1[1]\n",
    "    color1 = tuple1[2]\n",
    "    \n",
    "    links2 = tuple2[0]\n",
    "    distance2 = tuple2[1]\n",
    "    color2 = tuple2[2]\n",
    "    \n",
    "    \n",
    "    # always try to contruct list separately instead of mutating existing.\n",
    "    final_links = list()\n",
    "        \n",
    "    if len(links1) > 0:\n",
    "        final_links.extend(links1)\n",
    "    if len(links2) > 0:\n",
    "        final_links.extend(links2)\n",
    "        \n",
    "    # links1.extend(links2)\n",
    "    # final_links = links1\n",
    "\n",
    "    \n",
    "    final_distance = min(distance1,distance2)\n",
    "    \n",
    "    final_color = None\n",
    "    \n",
    "    if color1 == 'WHITE':\n",
    "        final_color = color2\n",
    "    \n",
    "    elif color1 == 'GRAY':\n",
    "        if color2 == 'BLACK':\n",
    "            final_color = color2\n",
    "        else:\n",
    "            final_color = color1\n",
    "    else:\n",
    "        final_color = color1\n",
    "        \n",
    "    return (final_links,final_distance,final_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing iteration #0\n",
      "6597\n",
      "processing iteration #1\n",
      "10940\n",
      "processing iteration #2\n",
      "221938\n",
      "processing iteration #3\n",
      "342607\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# no of iterations for mapper and reducer\n",
    "\n",
    "degree_of_separation = -1\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    print(f\"processing iteration #{i}\")\n",
    "    \n",
    "    degree_of_separation += 1\n",
    "\n",
    "    \n",
    "    mapped_reducable_rdd = adjacency_list_rdd.flatMap(process_each_element)\n",
    "\n",
    "    # In this for loop, you just applied transformation, no action is there so above transformations won't \n",
    "    # get executed. In order to execute that, I am applying this action\n",
    "    print(mapped_reducable_rdd.count())\n",
    "    \n",
    "    if(count.value > 0):\n",
    "        break\n",
    "        \n",
    "    # this adjacency_list_rdd name must be same as the name of above adjacency_list_rdd, so that we can continue the\n",
    "    # process on modified rdd --> V. IM\n",
    "    adjacency_list_rdd = mapped_reducable_rdd.reduceByKey(reducer_of_superheros)\n",
    "    \n",
    "    \n",
    "print(degree_of_separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "a.extend([7,8,9])\n",
    "\n",
    "A = []\n",
    "B = [1,2,3,4]\n",
    "\n",
    "A.extend(B)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
